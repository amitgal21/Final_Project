{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGMerRDwqli9xHGbWTl0UB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitgal21/Final_Project/blob/main/Identify_Gram_Pos%26Neg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage, we are training our model on 80% of the dataset, and 20% is reserved for validation. Through these segmentation operations, we are essentially training and predicting images of bacteria that were stained using Gram staining.\n",
        "\n",
        "Using the VGG16 model, we train our model on our dataset to distinguish between positive and negative Gram bacteria. The learning process is computationally intensive for personal computers, so we use Google Colab and allocate a sum of money to Google Colab to gain additional computational power.\n",
        "\n",
        "This allows us to perform the training process, during which we can train the system for approximately 3 hours, instead of an entire day on a regular computer.\n"
      ],
      "metadata": {
        "id": "Zl_66b2fai-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Connect to Google Drive for Using Our DataSet Of Bacteria Images"
      ],
      "metadata": {
        "id": "1oDdiOWZa5zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "script is aimed at training a Convolutional Neural Network (CNN) model for classifying images of purple and red bacteria using transfer learning with the VGG16 architecture.\n",
        "\n",
        "Here's a detailed explanation of each part of the code:\n",
        "\n",
        "Importing necessary libraries: The script starts by importing required libraries for its operation, including NumPy for data processing, os for file system navigation, PIL for image processing, scikit-learn for data operations, Matplotlib for plotting graphs, and TensorFlow for model development and training.\n",
        "\n",
        "Image preprocessing functions: Defines a function named preprocess_image for image preprocessing, and another function named load_tiff_images_from_folder for loading images from directories and assigning labels based on their folder names.\n",
        "\n",
        "Paths to datasets: Defines paths to directories containing images of Positive and Negative Gram Staining photos.\n",
        "\n",
        "Loading and labeling images: Utilizes the functions defined earlier to load images from the specified directories, preprocess them, and assign labels accordingly.\n",
        "\n",
        "Combining datasets: Merges the loaded images and labels into sequential arrays using NumPy.\n",
        "\n",
        "Splitting dataset into training and validation sets: Splits the data into training and validation sets using scikit-learn's train_test_split function.\n",
        "\n",
        "Loading VGG16 model: Loads the VGG16 model pre-trained on the ImageNet dataset without its top layers.\n",
        "\n",
        "Freezing base model layers: Freezes the layers of the pre-trained VGG16 model to prevent them from being updated during training.\n",
        "\n",
        "Adding new layers: Adds new dense layers for binary classification on top of the VGG16 base model.\n",
        "\n",
        "Compiling the model: Configures the model for training with an Adam optimizer and binary cross-entropy loss function.\n",
        "\n",
        "Setting up Data Generator: Creates an ImageDataGenerator for data augmentation during training.\n",
        "\n",
        "Preparing Data Generator for training: Configures the data generator for training using the flow method.\n",
        "\n",
        "Training the model: Fits the model to the training data with the specified number of epochs, using the data generator for augmented images.\n",
        "\n",
        "Saving the model: Saves the trained model to a file for future use.\n",
        "\n",
        "This script essentially performs transfer learning using the VGG16 model to classify images of Positive and Negative Gram Staining photos"
      ],
      "metadata": {
        "id": "4N27QbqAbZmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(img):\n",
        "    img = img.resize((224, 224))  # Resize the image to match VGG16 input size\n",
        "    img = np.array(img)\n",
        "    if img.ndim == 2:  # Convert grayscale to RGB if necessary\n",
        "        img = np.stack((img,)*3, axis=-1)\n",
        "    img = img / 255.0  # Normalize the image\n",
        "    return img\n",
        "\n",
        "# Function to load images from a folder\n",
        "def load_tiff_images_from_folder(folder, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        if img_path.lower().endswith('.tif'):\n",
        "            img = Image.open(img_path)\n",
        "            img = preprocess_image(img)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Paths to datasets\n",
        "train_path_purple = '/content/drive/My Drive/Part_B/DataSet_Stage1/Purple_Bacteria'\n",
        "train_path_red = '/content/drive/My Drive/Part_B/DataSet_Stage1/Red_Bacteria'\n",
        "\n",
        "# Loading and labeling images\n",
        "purple_images, purple_labels = load_tiff_images_from_folder(train_path_purple, 0)\n",
        "red_images, red_labels = load_tiff_images_from_folder(train_path_red, 1)\n",
        "\n",
        "# Combining datasets and converting to numpy arrays\n",
        "all_images = np.array(purple_images + red_images)\n",
        "all_labels = np.array(purple_labels + red_labels)\n",
        "\n",
        "# Splitting dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Loading VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the weights of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding new layers to the model\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification layer\n",
        "\n",
        "# Creating the new model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Setting up the Data Generator\n",
        "data_gen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n",
        "\n",
        "# Preparing the Data Generator for training\n",
        "train_gen = data_gen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "# Training the model\n",
        "model.fit(train_gen, epochs=10, validation_data=(X_val, y_val), steps_per_epoch=len(X_train) // 32)\n",
        "\n",
        "# Saving the model\n",
        "model.save('/content/drive/My Drive/trained_vgg16_model.h5')"
      ],
      "metadata": {
        "id": "rqXVqdf8a_gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code loads a pre-trained model that has already been trained to recognize red and purple bacteria. Then, it goes through new images of bacteria, processes each image, and predicts which type of bacteria is in the image - either Gram Positive and Gram Negative images.\n",
        "Positive Are Red and Negative are Purple.\n",
        "\n"
      ],
      "metadata": {
        "id": "xsgh1TWFc6HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.1: Load the Trained Model\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/My Drive/trained_vgg16_model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Modified Second preprocess_image Function\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    img = load_img(image, target_size=target_size)  # Load and resize the image\n",
        "    img = np.array(img)\n",
        "    if img.ndim == 2:  # Convert grayscale to RGB if necessary\n",
        "        img = np.stack((img,) * 3, axis=-1)\n",
        "    img = img / 255.0  # Normalize the image\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Define the path to the verify images\n",
        "verify_path = '/content/drive/MyDrive/Part_B/DataSet_Stage1/Red_Veirfy_test'\n",
        "\n",
        "# Read each file in the verify directory and predict\n",
        "for filename in os.listdir(verify_path):\n",
        "    if filename.endswith('.tif'): # Check the file extension\n",
        "        image_path = os.path.join(verify_path, filename)\n",
        "        new_image = preprocess_image(image_path)\n",
        "\n",
        "        # Step 3.3: Use the Model to Predict the Class of the New Image\n",
        "        prediction = model.predict(new_image)\n",
        "        predicted_class = 'Purple' if prediction[0][0] < 0.5 else 'Red'\n",
        "        print(f\"File: {filename}, Predicted class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "DqsIHUN_dTub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}