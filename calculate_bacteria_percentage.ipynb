{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMasrlWHu6pPViyIO0+pKJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitgal21/Final_Project/blob/main/calculate_bacteria_percentage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage, we are training the U-Net architecture, which deals with segmentation tasks on images with small objects. Therefore, for our project, which involves predicting and segmenting images of bacteria, the U-Net architecture is suitable. We combine it with the VGG16 model so that we can achieve high-quality prediction and segmentation results.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5mmDMSsZhw9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Connect to google drive for load the data set"
      ],
      "metadata": {
        "id": "0KfPG-7ciSaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade Pillow\n",
        "#install this pagacge for preprocess the images and for tarining our model"
      ],
      "metadata": {
        "id": "iDFqlhjgiU2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code loads images and their corresponding segmentations from a directory. It then defines a U-Net architecture combined with the VGG16 model for segmenting these images. After compiling the model, it trains it on the loaded data and saves the trained model to a file. Overall, the code performs image segmentation on bacteria images using the U-Net architecture with VGG16 as a base model and saves the trained model for future use."
      ],
      "metadata": {
        "id": "yxW-hnH4jHb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "def load_images_and_segmentations(data_dir):\n",
        "    images = []\n",
        "    segmentations = []\n",
        "\n",
        "    for subdir in os.listdir(data_dir):\n",
        "        subdir_path = os.path.join(data_dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            for filename in os.listdir(subdir_path):\n",
        "                if filename.lower().endswith('.tif') and not '_segmentation.tif' in filename:\n",
        "                    try:\n",
        "                        img_path = os.path.join(subdir_path, filename)\n",
        "                        img = Image.open(img_path)\n",
        "                        img = img.resize((224, 224))\n",
        "                        img = np.array(img)\n",
        "                        if img.ndim == 2:\n",
        "                            img = np.stack((img,) * 3, axis=-1)\n",
        "                        img = img / 255.0\n",
        "                        images.append(img)\n",
        "\n",
        "                        segmentation_path = img_path.replace('.tif', '_segmentation.tif')\n",
        "                        segmentation = Image.open(segmentation_path)\n",
        "                        segmentation = segmentation.resize((224, 224))\n",
        "                        segmentation = np.array(segmentation)\n",
        "                        if segmentation.ndim == 2:\n",
        "                            segmentation = np.expand_dims(segmentation, axis=-1)\n",
        "                        segmentation = segmentation.astype('float32') / 255.0\n",
        "                        segmentations.append(segmentation)\n",
        "                        print(f\"Segmentation loaded: {filename.replace('.tif', '_segmentation.tif')}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading {img_path}: {e}\")\n",
        "    return np.array(images), np.array(segmentations)\n",
        "\n",
        "\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/drive/MyDrive/Part_B/Datset3/Learn'\n",
        "\n",
        "images, segmentations = load_images_and_segmentations(data_dir)\n",
        "\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "\n",
        "def vgg16_unet(input_size=(224, 224, 3), num_classes=34):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_size)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    block1_pool = base_model.get_layer('block1_pool').output\n",
        "    block2_pool = base_model.get_layer('block2_pool').output\n",
        "    block3_pool = base_model.get_layer('block3_pool').output\n",
        "    block4_pool = base_model.get_layer('block4_pool').output\n",
        "    block5_pool = base_model.get_layer('block5_pool').output\n",
        "\n",
        "    u6 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(block5_pool)\n",
        "    u6 = concatenate([u6, block4_pool])\n",
        "    u6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    u6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "\n",
        "    u7 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(u6)\n",
        "    u7 = concatenate([u7, block3_pool])\n",
        "    u7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    u7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "\n",
        "    u8 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(u7)\n",
        "    u8 = concatenate([u8, block2_pool])\n",
        "    u8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    u8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "\n",
        "    u9 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(u8)\n",
        "    u9 = concatenate([u9, block1_pool])\n",
        "    u9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    u9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "\n",
        "    u10 = UpSampling2D((2, 2))(u9)\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(u10)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = vgg16_unet()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "segmentations_one_hot = tf.keras.utils.to_categorical(segmentations, num_classes=34)\n",
        "\n",
        "model.fit(images, segmentations_one_hot, batch_size=32, epochs=10, validation_split=0.2)\n",
        "\n",
        "model_save_path = '/content/drive/My Drive/trained_model_unet.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "xPTTLovhilUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code snippet loads a pre-trained U-Net model for image segmentation from a specified path. It then defines functions to load and prepare an image for inference, calculate the area and percentage of bacteria in the segmented image, and process images from a directory by predicting segmentation maps and analyzing them."
      ],
      "metadata": {
        "id": "xOt7pWRbjUZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Load the trained U-Net model for image segmentation\n",
        "model_path = '/content/drive/My Drive/trained_model_unet.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "def load_and_prepare_image(image_path):\n",
        "    \"\"\"\n",
        "    Load and prepare an image for inference.\n",
        "\n",
        "    Parameters:\n",
        "        image_path (str): The path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The preprocessed image ready for prediction.\n",
        "    \"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224, 224))  # Resize image to match model input size\n",
        "    img = np.array(img)\n",
        "    if img.ndim == 2:  # If the image is grayscale, convert it to RGB\n",
        "        img = np.stack((img,) * 3, axis=-1)\n",
        "    img = img / 255.0  # Normalize pixel values to range [0, 1]\n",
        "    img = np.expand_dims(img, axis=0)  # Add a batch dimension to the image\n",
        "    return img\n",
        "\n",
        "def calculate_bacteria_area(segmentation, pixel_size=1.0):\n",
        "    \"\"\"\n",
        "    Calculate the area and percentage of bacteria in the segmented image.\n",
        "\n",
        "    Parameters:\n",
        "        segmentation (numpy.ndarray): The segmentation map where each pixel's value represents a class.\n",
        "        pixel_size (float): The size of each pixel in micrometers.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the area of bacteria in square micrometers and the percentage of area covered by bacteria.\n",
        "    \"\"\"\n",
        "    bacteria_pixels = np.sum(segmentation > 0)  # Count all the bacteria pixels\n",
        "    total_pixels = segmentation.size  # Total pixels in the image\n",
        "    area = bacteria_pixels * pixel_size * pixel_size  # Calculate the area in square micrometers\n",
        "    percentage = (bacteria_pixels / total_pixels) * 100  # Calculate the percentage of area covered by bacteria\n",
        "    return area, percentage\n",
        "\n",
        "def process_images_from_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Process images from a directory by predicting segmentation maps and analyzing them.\n",
        "\n",
        "    Parameters:\n",
        "        directory_path (str): The path to the directory containing the images.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.lower().endswith('.tif'):  # Process only TIFF image files\n",
        "            image_path = os.path.join(directory_path, filename)\n",
        "            img = load_and_prepare_image(image_path)  # Load and prepare the image\n",
        "            pred = model.predict(img)  # Predict segmentation map using the trained model\n",
        "            segmentation = np.argmax(pred, axis=-1)[0]  # Extract segmentation map from predictions\n",
        "            bacteria_area, bacteria_percentage = calculate_bacteria_area(segmentation)  # Calculate bacteria area and percentage\n",
        "            print(f\"Bacteria area in {filename}: {bacteria_area} square micrometers, which is {bacteria_percentage:.2f}% of the image\")\n",
        "\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/Part_B/Datset3/Verify/a'\n",
        "process_images_from_directory(directory_path)\n"
      ],
      "metadata": {
        "id": "R381LM8PjSnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this code is to train a U-Net model architecture to estimate the percentage of bacteria in an image. We aim to extract these vital data points in order to accurately assess the type of bacteria present."
      ],
      "metadata": {
        "id": "y2A0-LaJkOd-"
      }
    }
  ]
}