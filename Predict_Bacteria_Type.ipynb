{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiZbRsj9F+uYW5MtCAZEST",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitgal21/Final_Project/blob/main/Predict_Bacteria_Type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this part of the code is bacterial type prediction using artificial intelligence. This operation does not involve the use of segmentation images, as we are conducting a prediction process here rather than analyzing image statistics."
      ],
      "metadata": {
        "id": "wGr_7-coyftL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates the process of preparing and training an image classification model using TensorFlow and Keras, with the VGG16 architecture as the base. Initially, it loads and processes images from a given directory, resizing each image to a standard size and normalizing them (scaling the pixel values of each image to a range between 0 and 1). The labels for the images are derived from the names of the folders containing them and are then converted to a numeric format using LabelEncoder and subsequently translated into a one-hot format to fit the model's requirements for classification. Additionally, the code performs a split of the data into training and validation sets and creates a data augmentation configuration to increase the diversity of the training data and prevent overfitting.\n",
        "\n",
        "After preparing the data, the code defines a model with VGG16 as the non-trainable base layer (meaning its weights remain fixed) and adds a new classification head comprising dense layers, dropout layers to prevent overfitting, and an output layer with a softmax activation function intended for categorizing the images into various classes. The model is compiled with the Adam optimizer and categorical cross-entropy loss, typical for multi-class classification problems. Finally, the model is trained using a data flow generated by ImageDataGenerator, iterating over the previously defined training and validation sets with the augmentation configuration, and ultimately saved for future use.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZIZ3jRnYzV8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j9SxwQsyBYk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_images_and_labels(data_dir, target_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for subdir, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.tif') and '_segmentation' not in file.lower():\n",
        "                filepath = os.path.join(subdir, file)\n",
        "                img = tf.keras.preprocessing.image.load_img(filepath, target_size=target_size)\n",
        "                img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "                img /= 255.0  # Normalize images\n",
        "                images.append(img)\n",
        "                label = os.path.basename(subdir)\n",
        "                labels.append(label)\n",
        "    return np.array(images), labels\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Part_B/Datset3/Learn'\n",
        "images, labels = load_images_and_labels(data_dir)\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels_enc = le.fit_transform(labels)\n",
        "labels_enc = to_categorical(labels_enc, num_classes=len(le.classes_))\n",
        "\n",
        "class_indices = {class_label: index for index, class_label in enumerate(le.classes_)}\n",
        "class_indices_file_path = '/content/drive/MyDrive/Part_B/Trained_Models/class_indices.json'\n",
        "with open(class_indices_file_path, 'w') as file:\n",
        "    json.dump(class_indices, file)\n",
        "\n",
        "images_train, images_val, labels_train, labels_val = train_test_split(images, labels_enc, test_size=0.2, random_state=42)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow(images_train, labels_train, batch_size=32)\n",
        "validation_generator = val_datagen.flow(images_val, labels_val, batch_size=32)\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(le.classes_), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(images_train) // 32,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(images_val) // 32,\n",
        "    epochs=20)  # Increased number of epochs\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Part_B/Trained_Models/vgg16_model_improved.h5'\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(\"Model saved successfully at\", model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    img = load_img(image, target_size=target_size)\n",
        "    img = np.array(img)\n",
        "    if img.ndim == 2:\n",
        "        img = np.stack((img,) * 3, axis=-1)\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/Part_B/Trained_Models/vgg16_model_improved.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Load class indices\n",
        "class_indices_file_path = '/content/drive/MyDrive/Part_B/Trained_Models/class_indices.json'\n",
        "with open(class_indices_file_path, 'r') as file:\n",
        "    class_indices = json.load(file)\n",
        "index_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "root_path = '/content/drive/MyDrive/Part_B/Datset3/dataset4'\n",
        "\n",
        "# Iterate over all directories and subdirectories\n",
        "for subdir, dirs, files in os.walk(root_path):\n",
        "    for filename in files:\n",
        "        if filename.endswith('.tif'):\n",
        "            image_path = os.path.join(subdir, filename)\n",
        "            new_image = preprocess_image(image_path)\n",
        "            predictions = model.predict(new_image)\n",
        "            predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "            predicted_class_name = index_to_class[predicted_class_index]\n",
        "            print(f\"File: {filename}, Predicted class: {predicted_class_name} in folder {os.path.basename(subdir)}\")\n"
      ],
      "metadata": {
        "id": "13pVuvrLzeLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}